ETL-Retail-Orders-Project
ğŸš€ Overview
This project is a part of my Cloud Data Engineering learning journey, where we built an ETL (Extract, Transform, Load) pipeline to process retail order data. This project demonstrates an end-to-end data analytics workflow. Using Python for data preprocessing and SQL Server for data storage and analysis, the goal is to extract, clean, transform, and analyze sales data to uncover meaningful insights that drive business decisions.

ğŸ“Œ Key Features
Extract: Fetched retail order data using the Kaggle API.
Transform: Cleaned, processed, and optimized the dataset using pandas.
Load: Stored the refined data into SQL Server for querying and analysis.

ğŸ”§ Tech Stack
Python (pandas, requests)
Kaggle API
SQL Server
Jupyter Notebook

Project Steps: 
Task 1: Logging function
Task 2 : Extraction of data
Task 3 : Transformation of data
Task 4: Loading to CSV
Task 5: Loading to Database
Task 6: Function to Run queries on Database
Task 7: Verify log entries

 
âš¡ How to Run the Project
Clone the Repository
git clone https://github.com/akhtarcloudx/ETL-Retail-Orders-Project.git
cd Retail-Order-ETL
Set Up Kaggle API
Download your Kaggle API key from Kaggle.
Place the kaggle.json file in C:\Users\YourUsername\.kaggle\ (Windows).

Archiecture




ğŸ“Š Insights & Learnings
Gained hands-on experience with the ETL process.
Strengthened my Python (pandas) and SQL skills.
Learned how to use the Kaggle API for data extraction.
If you find this project useful, feel free to â­ the repo and contribute! Let's connect and grow together in the Data Engineering space. ğŸš€

ğŸ“¬ Connect with Me
LinkedIn | GitHub |

#DataEngineering #ETL #Python #SQL #Mentorship #Growth